{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [1. Data Overview](#data_review)\n",
    "    * [Conclusions](#data_review_conclusions)\n",
    "* [2. Data Pre-Processing](#data_preprocessing)\n",
    "    * [2.1 Standardize Column Names](#column_names)\n",
    "    * [2.2 Handling with Missing Values](#missing_values)\n",
    "    * [2.3 Drop Unused Columns](#drop_unused_cols)\n",
    "    * [2.4 Categorizing Columns](#categorizing_cols)\n",
    "    * [2.5 Encode Features](#encode)\n",
    "* [3. Splitting the Data](#splitting_data)\n",
    "* [4. Assessing Model Quality](#model_quality)\n",
    "    * [4.1 Logistic Regression](#initial_lr)\n",
    "    * [4.2 Decision Tree Classifier](#initial_dtree)\n",
    "    * [4.3 Random Forest](#initial_rf)\n",
    "    * [Conclusions](#model_quality_conclusions)\n",
    "* [5. Normalizing the features in the dataset using Standard Scaler](#scaling)\n",
    "    * [5.1 Logistic Regression](#scaling_lr)\n",
    "    * [5.2 Decision Tree](#scaling_dtree)\n",
    "    * [5.3 Random Forest](#scaling_rf)\n",
    "    * [Conclusions](#after_scaling_conclusions)\n",
    "* [6. Improving the model's quality](#improve)\n",
    "    * [6.1 Hyperparameter Tuning](#hyperparameter_tuning)\n",
    "    * [6.2 Upsampling](#upsampling)\n",
    "    * [6.3 Downsampling](#downsampling)\n",
    "    * [Conclusions](#after_improving_conclusions)\n",
    "* [7. Testing Model on Test Dataset](#testing_model)\n",
    "* [General Conclusion](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "In this project, I will predict whether the customers of Bank Beta is likely to leave the bank soon or not as the bank employees realize that it would be more cost-effective for the company to focus on retaining their loyal existing customers rather than attracting new ones. \n",
    "I have data related to the past behavior of clients and their history of contract terminations with the bank.\n",
    "\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "To train a model with the highest possible F1 score with a minimum F1 score of 0.59 for the test dataset. Additionally, I will measure the AUC-ROC metric and compare it with the F1 score.\n",
    "\n",
    "\n",
    "**This project will consist of three steps:**\n",
    "\n",
    "1. Data Overview\n",
    "2. Data Preprocessing\n",
    "3. Splitting the Data\n",
    "4. Assessing Model Quality\n",
    "5. Normalizing the Features in the dataset using Standard Scaler\n",
    "6. Improving the model's quality\n",
    "7. Testing model on test dataset\n",
    "\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview <a id='data_review'></a>\n",
    "\n",
    "The steps to be performed are as follows:\n",
    "1. Checking the number of rows and columns.\n",
    "2. Checking for missing values.\n",
    "3. Checking for duplicate data.\n",
    "4. Checking statistical information in columns with numerical data types.\n",
    "5. Checking values in columns with categorical data types.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "\n",
    "# dataset\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "# scientific computing\n",
    "import numpy as np\n",
    "\n",
    "# model libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# import Standard Scaler Standardize the features by removing the mean and scaling to unit variance using a standard scaler. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# testing model\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "# shuffle aray\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path = 'data/Churn.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Exploration: churn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0.00\n",
       "CustomerId         0.00\n",
       "Surname            0.00\n",
       "CreditScore        0.00\n",
       "Geography          0.00\n",
       "Gender             0.00\n",
       "Age                0.00\n",
       "Tenure             9.09\n",
       "Balance            0.00\n",
       "NumOfProducts      0.00\n",
       "HasCrCard          0.00\n",
       "IsActiveMember     0.00\n",
       "EstimatedSalary    0.00\n",
       "Exited             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "df.isnull().sum() / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data composition of target column in percentage\n",
    "df['exited'].value_counts()/df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion <a id='data_review_conclusions'></a>\n",
    "\n",
    "1. Column names are not standardized (mixed case).\n",
    "2. There are missing values in the 'tenure' column, totaling 909 data or around 9.09%. Since the percentage is not high, missing values will be filled using the median.\n",
    "3. Data types in the columns are correct.\n",
    "4. The composition of the target data is not ideal due to an imbalance. This implies that, since the majority of the target data is 1, there is a tendency for the model to predict the value 1. This can result in poor model performance and low accuracy. To address this imbalance, techniques like upsampling (increasing the frequency of value 0) or downsampling (reducing the frequency of value 1) can be employed. However, both upsampling and downsampling might lead to the introduction of synthetic data points.\n",
    "5. Columns that are not used will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preprocessing <a id='data_preprocessing'></a>\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standardize Column Names <a id='column_names'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   rownumber        10000 non-null  int64  \n",
      " 1   customerid       10000 non-null  int64  \n",
      " 2   surname          10000 non-null  object \n",
      " 3   creditscore      10000 non-null  int64  \n",
      " 4   geography        10000 non-null  object \n",
      " 5   gender           10000 non-null  object \n",
      " 6   age              10000 non-null  int64  \n",
      " 7   tenure           9091 non-null   float64\n",
      " 8   balance          10000 non-null  float64\n",
      " 9   numofproducts    10000 non-null  int64  \n",
      " 10  hascrcard        10000 non-null  int64  \n",
      " 11  isactivemember   10000 non-null  int64  \n",
      " 12  estimatedsalary  10000 non-null  float64\n",
      " 13  exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Handling Missing Values <a id='missing_values'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values in 'tenure' column with median value\n",
    "df['tenure'] = df['tenure'].fillna(value=df['tenure'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rownumber          0\n",
       "customerid         0\n",
       "surname            0\n",
       "creditscore        0\n",
       "geography          0\n",
       "gender             0\n",
       "age                0\n",
       "tenure             0\n",
       "balance            0\n",
       "numofproducts      0\n",
       "hascrcard          0\n",
       "isactivemember     0\n",
       "estimatedsalary    0\n",
       "exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "There are no more missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Drop Unused Column <a id='drop_unused_cols'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['rownumber', 'customerid', 'surname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Categorizing Columns <a id='categorizing_cols'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical columns\n",
    "df_categorical = ['geography', 'gender']\n",
    "\n",
    "# numerical columns\n",
    "df_numerical = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'hascrcard', 'isactivemember', 'estimatedsalary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore geography  gender  age  tenure    balance  numofproducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   hascrcard  isactivemember  estimatedsalary  exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Encode Features <a id='encode'></a>\n",
    "\n",
    "I will use get_dummies because the categorical columns do not have any order (they are not ordinal data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True, columns = df_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_Germany  \\\n",
       "0               1        101348.88       1              False   \n",
       "1               1        112542.58       0              False   \n",
       "2               0        113931.57       1              False   \n",
       "3               0         93826.63       0              False   \n",
       "4               1         79084.10       0              False   \n",
       "\n",
       "   geography_Spain  gender_Male  \n",
       "0            False        False  \n",
       "1             True        False  \n",
       "2            False        False  \n",
       "3            False        False  \n",
       "4             True        False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting Data <a id='splitting_data'></a>\n",
    "\n",
    "The data will be splitted into:\n",
    "1. Training Set: This data is used to train and build the model.\n",
    "2. Validation Set: This data is used to optimize the model during its construction. It helps assess the model's ability to recognize patterns in a general sense. The validation set is also used to evaluate the accuracy of the created model. If the accuracy is not satisfactory, hyperparameter tuning can be performed.\n",
    "3. Test Set: This data is used to test the model's performance.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into df_train_valid, df_test\n",
    "df_train_valid, df_test = train_test_split(df, test_size=0.15)\n",
    "\n",
    "# split df_train, df_valid from df_train_valid\n",
    "df_train, df_valid = train_test_split(df_train_valid, test_size=0.25)\n",
    "\n",
    "# Define features and target for training dataset\n",
    "features_train = df_train.drop('exited', axis=1)\n",
    "target_train = df_train['exited']\n",
    "\n",
    "# Define features and target for validation dataset\n",
    "features_valid = df_valid.drop('exited', axis=1)\n",
    "target_valid = df_valid['exited']\n",
    "\n",
    "# Define features and target for test dataset\n",
    "features_test = df_test.drop('exited', axis=1)\n",
    "target_test = df_test['exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6375, 11)\n",
      "(2125, 11)\n",
      "(1500, 11)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assessing Model Quality <a id='model_quality'></a>\n",
    "\n",
    "without hyperparameter tuning and before scalling.\n",
    "\n",
    "The assessment of model quality will use the following matrices:\n",
    "\n",
    "1. F1 score: The \"harmonic mean\" or \"harmonic average\" of precision and recall. The best F1-Score value is 1.0, and the worst is 0. In representation, a high F1-Score indicates that our classification model has good precision and recall.\n",
    "Source: [Understanding Precision, Recall, and F1-Score](https://stevkarta.medium.com/membicarakan-precision-recall-dan-f1-score-e96d81910354)\n",
    "\n",
    "2. AUC-ROC score:\n",
    "ROC (Receiver Operating Characteristics) is a performance measurement tool for classification problems used to determine the threshold of a model.\n",
    "AUC (Area Under the Curve) makes it easy to compare one model to another. AUC is the area under the ROC curve or the integral of the ROC function.\n",
    "And we should choose the model with the highest AUC since it has higher TP and/or lower FP for every point.\n",
    "Source: [Understanding ROC and AUC](https://datasans.medium.com/memahami-roc-dan-auc-2e0e4f3638bf)\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Logistic Regression <a id='initial_lr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.1140529531568228\n",
      "AUC-ROC score = 0.6700753101004134\n"
     ]
    }
   ],
   "source": [
    "beforeScaling_lr = LogisticRegression(random_state = 42)\n",
    "\n",
    "# train model on training set\n",
    "beforeScaling_lr.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_lr = beforeScaling_lr.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_lr = beforeScaling_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_lr))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Decision Tree Classifier <a id='initial_dtree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.47314285714285714\n",
      "AUC-ROC score = 0.6698845737349872\n"
     ]
    }
   ],
   "source": [
    "beforeScaling_dTree = DecisionTreeClassifier()\n",
    "\n",
    "# train model on training set\n",
    "beforeScaling_dTree.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_dtree = beforeScaling_dTree.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_dtree = beforeScaling_dTree.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_dtree))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Random Forest <a id='initial_rf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6107091172214182\n",
      "AUC-ROC score = 0.8696814526348492\n"
     ]
    }
   ],
   "source": [
    "beforeScaling_rf = RandomForestClassifier()\n",
    "\n",
    "# train model on training set\n",
    "beforeScaling_rf.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_rf = beforeScaling_rf.predict(features_valid)\n",
    "# menghitung probability\n",
    "y_probability_valid_lr = beforeScaling_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_rf))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion (before scalling and before hyperparameter tuning) <a id='model_quality_conclusions'></a>\n",
    "\n",
    "1. Based on the performance results of the three models, the F1 scores from highest to lowest are as follows:\n",
    "   - Random Forest model with an F1 score of 0.61 and an AUC-ROC score of 0.87\n",
    "   - Decision Tree model with an F1 score of 0.47 and an AUC-ROC score of 0.67\n",
    "   - Logistic Regression model with an F1 score of 0.11 and an AUC-ROC score of 0.67\n",
    "\n",
    "\n",
    "2. The results of Random Forest passed the evaluation with a minimum F1 score of 0.59 for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Normalizing the features in the dataset using Standard Scaler <a id='scaling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StandardScaler is a class from sklearn used to normalize data in order to eliminate large deviations in the data used.\n",
    "\n",
    "Source: [Building a Classification Model to Predict Legendary Pokémon](https://medium.com/codelabs-unikom/membangun-model-klasifikasi-untuk-mempredict-pokemon-legend-935d2accceaa#:~:text=StandardScaler%20is%20class%20dari%20sklearn,tidak%20memiliki%20penyimpangan%20yang%20besar.&text=Satu%20hal%20penting%20dalam%20Data,apa%20yang%20akan%20di%20analisis.)\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "features_train[df_numerical] = scaler.fit_transform(features_train[df_numerical])\n",
    "\n",
    "features_valid[df_numerical] = scaler.transform(features_valid[df_numerical])\n",
    "features_test[df_numerical] = scaler.transform(features_test[df_numerical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>-0.280615</td>\n",
       "      <td>-0.563822</td>\n",
       "      <td>0.357813</td>\n",
       "      <td>-1.215725</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>-1.534687</td>\n",
       "      <td>-1.030747</td>\n",
       "      <td>-0.408434</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182</th>\n",
       "      <td>0.194409</td>\n",
       "      <td>-0.755542</td>\n",
       "      <td>-1.092782</td>\n",
       "      <td>-0.294384</td>\n",
       "      <td>-0.917536</td>\n",
       "      <td>0.651599</td>\n",
       "      <td>0.970170</td>\n",
       "      <td>1.420323</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>-2.387242</td>\n",
       "      <td>-0.755542</td>\n",
       "      <td>-1.455431</td>\n",
       "      <td>0.519939</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>0.651599</td>\n",
       "      <td>0.970170</td>\n",
       "      <td>-1.565444</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>1.609154</td>\n",
       "      <td>-0.467962</td>\n",
       "      <td>-1.455431</td>\n",
       "      <td>-1.215725</td>\n",
       "      <td>-0.917536</td>\n",
       "      <td>-1.534687</td>\n",
       "      <td>-1.030747</td>\n",
       "      <td>0.249458</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>0.287348</td>\n",
       "      <td>-0.563822</td>\n",
       "      <td>0.357813</td>\n",
       "      <td>-1.215725</td>\n",
       "      <td>0.795789</td>\n",
       "      <td>0.651599</td>\n",
       "      <td>0.970170</td>\n",
       "      <td>-0.035811</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      creditscore       age    tenure   balance  numofproducts  hascrcard  \\\n",
       "1870    -0.280615 -0.563822  0.357813 -1.215725       0.795789  -1.534687   \n",
       "5182     0.194409 -0.755542 -1.092782 -0.294384      -0.917536   0.651599   \n",
       "4933    -2.387242 -0.755542 -1.455431  0.519939       0.795789   0.651599   \n",
       "6297     1.609154 -0.467962 -1.455431 -1.215725      -0.917536  -1.534687   \n",
       "3230     0.287348 -0.563822  0.357813 -1.215725       0.795789   0.651599   \n",
       "\n",
       "      isactivemember  estimatedsalary  geography_Germany  geography_Spain  \\\n",
       "1870       -1.030747        -0.408434              False             True   \n",
       "5182        0.970170         1.420323              False            False   \n",
       "4933        0.970170        -1.565444               True            False   \n",
       "6297       -1.030747         0.249458              False            False   \n",
       "3230        0.970170        -0.035811              False            False   \n",
       "\n",
       "      gender_Male  \n",
       "1870         True  \n",
       "5182        False  \n",
       "4933        False  \n",
       "6297        False  \n",
       "3230        False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression <a id='scaling_lr'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.3501683501683502\n",
      "AUC-ROC score = 0.7953927951448028\n"
     ]
    }
   ],
   "source": [
    "afterScaling_lr = LogisticRegression(random_state = 42)\n",
    "\n",
    "# train model on training set\n",
    "afterScaling_lr.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_lr = afterScaling_lr.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_lr = afterScaling_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_lr))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Decision Tree Classifier <a id='scaling_dtree'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.49944258639910816\n",
      "AUC-ROC score = 0.6873962724862174\n"
     ]
    }
   ],
   "source": [
    "afterScaling_dTree = DecisionTreeClassifier()\n",
    "# train model on training set\n",
    "afterScaling_dTree.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_dtree = afterScaling_dTree.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_dtree = afterScaling_dTree.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_dtree))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_dtree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Random Forest <a id='scaling_rf'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.6082036775106082\n",
      "AUC-ROC score = 0.8691909185795224\n"
     ]
    }
   ],
   "source": [
    "afterScaling_rf = RandomForestClassifier()\n",
    "# train model on training set\n",
    "afterScaling_rf.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_rf = afterScaling_rf.predict(features_valid)\n",
    "# menghitung probability\n",
    "y_probability_valid_lr = afterScaling_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_rf))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion <a id='after_scaling_conclusions'></a>\n",
    "\n",
    "1. Based on the performance results of the three models after scaling, the F1 scores from highest to lowest are as follows:\n",
    "   - Random Forest model with an F1 score of 0.61 and an AUC-ROC score of 0.87\n",
    "   - Decision Tree model with an F1 score of 0.50 and an AUC-ROC score of 0.69\n",
    "   - Logistic Regression model with an F1 score of 0.35 and an AUC-ROC score of 0.79\n",
    "\n",
    "2. The results of Random Forest passed the evaluation with a minimum F1 score of 0.59 for the validation set.\n",
    "\n",
    "3. When compared to the results before scaling, the Random Forest performance remained unchanged. Meanwhile, Logistic Regression improved by more than 3 times from 0.11 to 0.35, and Decision Treee increased by 0.03 for the F1 score and decreased by 0.02 for the AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Improving the model's quality <a id='improve'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 methods that will be used to improve the model's quality:\n",
    "\n",
    "1. Hyperparameter tuning for class_weight: Due to imbalance, hyperparameter tuning for class_weight will be performed with class_weight set to \"balanced.\" The model will automatically assign inverse class weights. This configuration helps in assigning a higher weight to the minority class and reducing the weight for the majority class. Source: [Improve Class Imbalance with Class Weights](https://www.analyticsvidhya.com/blog/2020/10/improve-class-imbalance-class-weights/)\n",
    "\n",
    "2. Upsampling: This procedure involves generating synthetic data points (matching the minority class) injected into the dataset. After this process, the count of both labels becomes nearly equal. This equalization procedure prevents the model from leaning towards the majority class. Furthermore, the interaction (decision boundary) between target classes remains unchanged. Upsampling also introduces bias into the system due to the added information. Source: [Handling Imbalanced Data - Upsampling](https://www.analyticsvidhya.com/blog/2020/11/handling-imbalanced-data-machine-learning-computer-vision-and-nlp/)\n",
    "\n",
    "3. Downsampling: This mechanism reduces the number of training samples from the majority class. It helps in balancing the number of target categories. However, by discarding accumulated data, we tend to lose a lot of valuable information. Source: [Handling Imbalanced Data - Downsampling](https://www.analyticsvidhya.com/blog/2020/11/handling-imbalanced-data-machine-learning-computer-vision-and-nlp/)\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Hyperparameter Tuning (class_weight) <a id='hyperparameter_tuning'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.1 Logistic Regression\n",
    "\n",
    "the hyperparameters that will be tuned are:\n",
    "- class_weight: balanced\n",
    "  (Explanation: When set to class_weight = balanced, the model will automatically assign inverse class weights. This configuration helps in assigning a higher weight to the minority class and reducing the weight for the majority class.)\n",
    "  Source: [Improve Class Imbalance with Class Weights](https://www.analyticsvidhya.com/blog/2020/10/improve-class-imbalance-class-weights/)\n",
    "- random_state: Controls the randomness of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5180327868852459\n",
      "AUC-ROC score = 0.7975715839072127\n"
     ]
    }
   ],
   "source": [
    "afterScaling_lr = LogisticRegression(random_state = 42, class_weight ='balanced')\n",
    "\n",
    "# train model on training set\n",
    "afterScaling_lr.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_lr = afterScaling_lr.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_lr = afterScaling_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_lr))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.2 Decission Tree Classifier\n",
    "\n",
    "The hyperparameters that will be tuned are:\n",
    "\n",
    "- max_depth: Limits the number of branches; if set too high, overfitting might occur.\n",
    "- class_weight: balanced\n",
    "  (Explanation: When set to class_weight = balanced, the model will automatically assign inverse class weights. This configuration helps in assigning a higher weight to the minority class and reducing the weight for the majority class.)\n",
    "  Source: [Improve Class Imbalance with Class Weights](https://www.analyticsvidhya.com/blog/2020/10/improve-class-imbalance-class-weights/)\n",
    "- random_state: Controls the randomness of the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at max_depth 1 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.49515418502202646\n",
      "AUC-ROC score = 0.6995458472204432\n",
      "\n",
      "at max_depth 2 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5248713550600342\n",
      "AUC-ROC score = 0.7666427304215595\n",
      "\n",
      "at max_depth 3 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5366726296958856\n",
      "AUC-ROC score = 0.8089758193962616\n",
      "\n",
      "at max_depth 4 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5318985395849346\n",
      "AUC-ROC score = 0.818614813583433\n",
      "\n",
      "at max_depth 5 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5748502994011977\n",
      "AUC-ROC score = 0.8387669063924762\n",
      "\n",
      "at max_depth 6 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5616883116883117\n",
      "AUC-ROC score = 0.8376652486598882\n",
      "\n",
      "at max_depth 7 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5729827742520398\n",
      "AUC-ROC score = 0.8196694618023855\n",
      "\n",
      "at max_depth 8 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5511265164644714\n",
      "AUC-ROC score = 0.7971825631494467\n",
      "\n",
      "at max_depth 9 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5461187214611872\n",
      "AUC-ROC score = 0.7681729241552595\n",
      "\n",
      "at max_depth 10 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.529520295202952\n",
      "AUC-ROC score = 0.7405742518674359\n",
      "\n",
      "at max_depth 11 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.518095238095238\n",
      "AUC-ROC score = 0.7323196537919645\n",
      "\n",
      "at max_depth 12 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5182341650671785\n",
      "AUC-ROC score = 0.7290909858916956\n",
      "\n",
      "at max_depth 13 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.518444666001994\n",
      "AUC-ROC score = 0.7207144355996916\n",
      "\n",
      "at max_depth 14 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5182012847965738\n",
      "AUC-ROC score = 0.7037637587989546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 15):\n",
    "    model_dtree = DecisionTreeClassifier(max_depth=depth, random_state = 42, class_weight ='balanced')\n",
    "    model_dtree.fit(features_train, target_train)\n",
    "    predictions_valid_dtree = model_dtree.predict(features_valid)\n",
    "    probabalities_valid_dtree = model_dtree.predict_proba(features_valid)[:, 1]\n",
    "    \n",
    "    print(\"at max_depth\", depth, \"F1 score and AUC-SCORE is:\", end='')\n",
    "    print()\n",
    "    print('F1 score =', f1_score(target_valid, predictions_valid_dtree))\n",
    "    print('AUC-ROC score =', roc_auc_score(target_valid, probabalities_valid_dtree))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1.3 Random Forest\n",
    "\n",
    "The hyperparameters that will be tuned are:\n",
    "- class_weight: balanced\n",
    "  (Explanation: When set to class_weight = balanced, the model will automatically assign inverse class weights. This configuration helps in assigning a higher weight to the minority class and reducing the weight for the majority class.)\n",
    "  Source: [Improve Class Imbalance with Class Weights](https://www.analyticsvidhya.com/blog/2020/10/improve-class-imbalance-class-weights/)\n",
    "- random_state: Controls the randomness of the estimator.\n",
    "- n_estimators: Determines the number of trees in the random forest model. As the number of estimators increases, the variance of predictions decreases. Therefore, the more trees used, the better the results obtained.\n",
    "- max_depth: Limits the number of branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At depth 1 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5510204081632654\n",
      "AUC-ROC score = 0.8260852384676807\n",
      "\n",
      "At depth 1 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5570698466780238\n",
      "AUC-ROC score = 0.8264401943604934\n",
      "\n",
      "At depth 1 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5321100917431193\n",
      "AUC-ROC score = 0.8188989145571431\n",
      "\n",
      "At depth 1 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5316455696202532\n",
      "AUC-ROC score = 0.8188430481786197\n",
      "\n",
      "At depth 1 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5314333612740989\n",
      "AUC-ROC score = 0.8204999632099459\n",
      "\n",
      "At depth 2 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.570446735395189\n",
      "AUC-ROC score = 0.8458728372217241\n",
      "\n",
      "At depth 2 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5706760316066725\n",
      "AUC-ROC score = 0.8433854207828378\n",
      "\n",
      "At depth 2 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5614035087719299\n",
      "AUC-ROC score = 0.8404919511537089\n",
      "\n",
      "At depth 2 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5618964003511852\n",
      "AUC-ROC score = 0.8408448631546245\n",
      "\n",
      "At depth 2 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.562610229276896\n",
      "AUC-ROC score = 0.8405519053160265\n",
      "\n",
      "At depth 3 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5927927927927927\n",
      "AUC-ROC score = 0.8579127230908006\n",
      "\n",
      "At depth 3 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5887600356824264\n",
      "AUC-ROC score = 0.8567156837363433\n",
      "\n",
      "At depth 3 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5841495992876223\n",
      "AUC-ROC score = 0.8547555914069334\n",
      "\n",
      "At depth 3 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5890909090909091\n",
      "AUC-ROC score = 0.8546275075147092\n",
      "\n",
      "At depth 3 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.590990990990991\n",
      "AUC-ROC score = 0.854121303621504\n",
      "\n",
      "At depth 4 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6053357865685373\n",
      "AUC-ROC score = 0.8626395637517134\n",
      "\n",
      "At depth 4 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6042632066728453\n",
      "AUC-ROC score = 0.86457308548646\n",
      "\n",
      "At depth 4 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6062846580406654\n",
      "AUC-ROC score = 0.8648142647303289\n",
      "\n",
      "At depth 4 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6029411764705882\n",
      "AUC-ROC score = 0.8641942841881798\n",
      "\n",
      "At depth 4 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5998160073597055\n",
      "AUC-ROC score = 0.8640989025663107\n",
      "\n",
      "At depth 5 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6046511627906977\n",
      "AUC-ROC score = 0.8697972731756902\n",
      "\n",
      "At depth 5 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6078066914498141\n",
      "AUC-ROC score = 0.8706502573941195\n",
      "\n",
      "At depth 5 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6076421248835042\n",
      "AUC-ROC score = 0.8701801622577648\n",
      "\n",
      "At depth 5 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6063432835820896\n",
      "AUC-ROC score = 0.870507184961316\n",
      "\n",
      "At depth 5 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6084507042253521\n",
      "AUC-ROC score = 0.8701610859333909\n",
      "\n",
      "At depth 6 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6204933586337761\n",
      "AUC-ROC score = 0.8749288044322476\n",
      "\n",
      "At depth 6 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6221374045801527\n",
      "AUC-ROC score = 0.8750528005406776\n",
      "\n",
      "At depth 6 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6215443279313632\n",
      "AUC-ROC score = 0.8747775564318552\n",
      "\n",
      "At depth 6 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6216730038022814\n",
      "AUC-ROC score = 0.8750677890812569\n",
      "\n",
      "At depth 6 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.623574144486692\n",
      "AUC-ROC score = 0.8752326630276307\n",
      "\n",
      "At depth 7 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6285160038797285\n",
      "AUC-ROC score = 0.8762259944896673\n",
      "\n",
      "At depth 7 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6348588120740019\n",
      "AUC-ROC score = 0.8769386314644894\n",
      "\n",
      "At depth 7 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6302439024390244\n",
      "AUC-ROC score = 0.8768623261669941\n",
      "\n",
      "At depth 7 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6296296296296297\n",
      "AUC-ROC score = 0.8772206885463024\n",
      "\n",
      "At depth 7 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6316812439261419\n",
      "AUC-ROC score = 0.8771525588163959\n",
      "\n",
      "At depth 8 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6526104417670683\n",
      "AUC-ROC score = 0.8786732143879088\n",
      "\n",
      "At depth 8 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6479438314944834\n",
      "AUC-ROC score = 0.8786173480093855\n",
      "\n",
      "At depth 8 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6452905811623245\n",
      "AUC-ROC score = 0.8781826803325822\n",
      "\n",
      "At depth 8 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6479999999999999\n",
      "AUC-ROC score = 0.8781022872512924\n",
      "\n",
      "At depth 8 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6458752515090543\n",
      "AUC-ROC score = 0.878243997089498\n",
      "\n",
      "At depth 9 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6339937434827945\n",
      "AUC-ROC score = 0.8756291780556864\n",
      "\n",
      "At depth 9 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6365546218487397\n",
      "AUC-ROC score = 0.8770408260593492\n",
      "\n",
      "At depth 9 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6415094339622641\n",
      "AUC-ROC score = 0.8777997912505076\n",
      "\n",
      "At depth 9 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6408376963350786\n",
      "AUC-ROC score = 0.8780464208727691\n",
      "\n",
      "At depth 9 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6450261780104711\n",
      "AUC-ROC score = 0.8780014552510307\n",
      "\n",
      "At depth 10 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6622516556291391\n",
      "AUC-ROC score = 0.8765584675716112\n",
      "\n",
      "At depth 10 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6430155210643015\n",
      "AUC-ROC score = 0.8761783036787328\n",
      "\n",
      "At depth 10 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6422222222222222\n",
      "AUC-ROC score = 0.8763445402197046\n",
      "\n",
      "At depth 10 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6473859844271412\n",
      "AUC-ROC score = 0.8764794370849195\n",
      "\n",
      "At depth 10 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6510590858416945\n",
      "AUC-ROC score = 0.8762641471384149\n",
      "\n",
      "At depth 11 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6619552414605419\n",
      "AUC-ROC score = 0.8773160701681714\n",
      "\n",
      "At depth 11 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.651658767772512\n",
      "AUC-ROC score = 0.8763104753547515\n",
      "\n",
      "At depth 11 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6548463356973995\n",
      "AUC-ROC score = 0.8771171313568445\n",
      "\n",
      "At depth 11 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6486486486486486\n",
      "AUC-ROC score = 0.8772724671410312\n",
      "\n",
      "At depth 11 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6501766784452296\n",
      "AUC-ROC score = 0.8767478682207511\n",
      "\n",
      "At depth 12 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6517967781908304\n",
      "AUC-ROC score = 0.8723371495066046\n",
      "\n",
      "At depth 12 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.655819774718398\n",
      "AUC-ROC score = 0.8734367633472954\n",
      "\n",
      "At depth 12 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6608260325406758\n",
      "AUC-ROC score = 0.875487468217481\n",
      "\n",
      "At depth 12 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6592039800995024\n",
      "AUC-ROC score = 0.8762491585978358\n",
      "\n",
      "At depth 12 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6583541147132169\n",
      "AUC-ROC score = 0.8755705864879668\n",
      "\n",
      "At depth 13 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6562091503267974\n",
      "AUC-ROC score = 0.8719556230191282\n",
      "\n",
      "At depth 13 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6492829204693611\n",
      "AUC-ROC score = 0.8741657514572949\n",
      "\n",
      "At depth 13 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6544980443285529\n",
      "AUC-ROC score = 0.8752844416223597\n",
      "\n",
      "At depth 13 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6511024643320363\n",
      "AUC-ROC score = 0.8760720213000788\n",
      "\n",
      "At depth 13 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6511024643320363\n",
      "AUC-ROC score = 0.8763649791386767\n",
      "\n",
      "At depth 14 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6292749658002736\n",
      "AUC-ROC score = 0.8767110781666017\n",
      "\n",
      "At depth 14 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6291208791208791\n",
      "AUC-ROC score = 0.8764957882200974\n",
      "\n",
      "At depth 14 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6377204884667571\n",
      "AUC-ROC score = 0.8763963188144338\n",
      "\n",
      "At depth 14 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6359945872801084\n",
      "AUC-ROC score = 0.8756537047584528\n",
      "\n",
      "At depth 14 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6344086021505375\n",
      "AUC-ROC score = 0.8764031317874243\n",
      "\n",
      "At depth 15 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6153846153846153\n",
      "AUC-ROC score = 0.8723500941552865\n",
      "\n",
      "At depth 15 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6215469613259669\n",
      "AUC-ROC score = 0.8742004976195472\n",
      "\n",
      "At depth 15 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6317241379310345\n",
      "AUC-ROC score = 0.8748238846481917\n",
      "\n",
      "At depth 15 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6325966850828729\n",
      "AUC-ROC score = 0.8747169209722385\n",
      "\n",
      "At depth 15 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6298342541436464\n",
      "AUC-ROC score = 0.8744178314579492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "n_estimator_list = [100, 200, 300, 400, 500]\n",
    "\n",
    "for depth in max_depth_list:\n",
    "    for n_estimator in n_estimator_list:\n",
    "        model_rf = RandomForestClassifier(max_depth = depth, n_estimators = n_estimator, class_weight = 'balanced', random_state = 42)\n",
    "\n",
    "        model_rf.fit(features_train, target_train)\n",
    "        predictions_valid_rf = model_rf.predict(features_valid)\n",
    "        probabalities_valid_rf = model_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "        print(\"At depth\", depth, \"and n_estimator\", n_estimator, \"F1 score and AUC-SCORE is:\", end='')\n",
    "        print()\n",
    "        print('F1 score =', f1_score(target_valid, predictions_valid_rf))\n",
    "        print('AUC-ROC score =', roc_auc_score(target_valid, probabalities_valid_rf))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "1. Based on the performance results of the models after tuning the hyperparameter, the F1 scores from highest to lowest are as follows:\n",
    "   - Random Forest model with depth = 10 and n_estimators = =100, F1 score = 0.662 and AUC-ROC score = 0.876\n",
    "   - Decision Tree model with depth = 7, F1 score = 0.57 and AUC-ROC score = 0.82\n",
    "   - Logistic Regression model with F1 score = 0.51 and AUC-ROC score = 0.79\n",
    "   \n",
    "\n",
    "2. The results of Random Forest passed the evaluation with a minimum F1 score of 0.59 for the validation set.\n",
    "\n",
    "3. Comparison of the three models before scaling, after scaling, and after weight adjustment is as follows:\n",
    "\n",
    "    3.1. Logistic Regression\n",
    "    \n",
    "        3.1.1 Before scaling: F1 score = 0.11 and AUC-ROC = 0.67\n",
    "\n",
    "        3.1.2 After scaling: F1 score = 0.35 and AUC-ROC = 0.79\n",
    "        \n",
    "        3.1.3 After class weight adjustment: F1 score = 0.51 and AUC-ROC = 0.79\n",
    "        \n",
    "    3.2. Decision Tree\n",
    "\n",
    "        3.2.1 Before scaling: F1 score = 0.47 and AUC-ROC score = 0.67\n",
    "\n",
    "        3.2.2 After scaling: F1 score = 0.50 and AUC-ROC score = 0.69\n",
    "\n",
    "        3.2.3 After class weight adjustment: F1 score = 0.57 and AUC-ROC score = 0.82\n",
    "        \n",
    "    3.3. Random Forest\n",
    "    \n",
    "        3.3.1 Before scaling: F1 score = 0.61 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.2 After scaling: F1 score = 0.61 and AUC-ROC score = 0.87\n",
    "        \n",
    "        3.3.3 After class weight adjustment: F1 score = 0.66 and AUC-ROC score = 0.87\n",
    "\n",
    "4. From the information above, it is evident that the F1 score of all three models increased after class weight adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Upsampling <a id='upsampling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample (features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle (features_upsampled, target_upsampled, random_state = 42)\n",
    "    \n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exited\n",
       "0    5068\n",
       "1    1307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data composition\n",
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exited\n",
       "1    5228\n",
       "0    5068\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data composition after upsampling\n",
    "target_upsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5188755020080321\n",
      "AUC-ROC score = 0.7975906602315865\n"
     ]
    }
   ],
   "source": [
    "upsample_lr = LogisticRegression(random_state = 42)\n",
    "\n",
    "# train model on training set\n",
    "upsample_lr.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_lr = upsample_lr.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_lr = upsample_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_lr))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At max_depth 1 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.49515418502202646\n",
      "AUC-ROC score = 0.6995458472204432\n",
      "\n",
      "At max_depth 2 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5248713550600342\n",
      "AUC-ROC score = 0.7666427304215595\n",
      "\n",
      "At max_depth 3 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5366726296958856\n",
      "AUC-ROC score = 0.8089758193962616\n",
      "\n",
      "At max_depth 4 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5318985395849346\n",
      "AUC-ROC score = 0.818614813583433\n",
      "\n",
      "At max_depth 5 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5748502994011977\n",
      "AUC-ROC score = 0.8387669063924762\n",
      "\n",
      "At max_depth 6 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5600649350649352\n",
      "AUC-ROC score = 0.8350449792476842\n",
      "\n",
      "At max_depth 7 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5793721973094171\n",
      "AUC-ROC score = 0.8223292464579354\n",
      "\n",
      "At max_depth 8 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.546712802768166\n",
      "AUC-ROC score = 0.8041658604648627\n",
      "\n",
      "At max_depth 9 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5479204339963835\n",
      "AUC-ROC score = 0.7758293432021518\n",
      "\n",
      "At max_depth 10 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5272727272727272\n",
      "AUC-ROC score = 0.7470929044248896\n",
      "\n",
      "At max_depth 11 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5079662605435802\n",
      "AUC-ROC score = 0.7270423249134073\n",
      "\n",
      "At max_depth 12 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5051449953227315\n",
      "AUC-ROC score = 0.7266764682638092\n",
      "\n",
      "At max_depth 13 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5094152626362735\n",
      "AUC-ROC score = 0.7191794727848981\n",
      "\n",
      "At max_depth 14 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5211864406779662\n",
      "AUC-ROC score = 0.7090349560018204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 15):\n",
    "    model_dtree = DecisionTreeClassifier(max_depth=depth, random_state = 42)\n",
    "    model_dtree.fit(features_upsampled, target_upsampled)\n",
    "    predictions_valid_dtree = model_dtree.predict(features_valid)\n",
    "    probabalities_valid_dtree = model_dtree.predict_proba(features_valid)[:, 1]\n",
    "    \n",
    "    print(\"At max_depth\", depth, \"F1 score and AUC-SCORE is:\", end='')\n",
    "    print()\n",
    "    print('F1 score =', f1_score(target_valid, predictions_valid_dtree))\n",
    "    print('AUC-ROC score =', roc_auc_score(target_valid, probabalities_valid_dtree))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At depth 1 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5378548895899053\n",
      "AUC-ROC score = 0.8230739044058133\n",
      "\n",
      "At depth 1 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5267175572519085\n",
      "AUC-ROC score = 0.8247825980318684\n",
      "\n",
      "At depth 1 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5236947791164659\n",
      "AUC-ROC score = 0.8185364643940405\n",
      "\n",
      "At depth 1 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5236947791164659\n",
      "AUC-ROC score = 0.8175867359591439\n",
      "\n",
      "At depth 1 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5269076305220883\n",
      "AUC-ROC score = 0.8189738572600402\n",
      "\n",
      "At depth 2 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5649622799664711\n",
      "AUC-ROC score = 0.8407126914786058\n",
      "\n",
      "At depth 2 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5626598465473146\n",
      "AUC-ROC score = 0.8392622095288965\n",
      "\n",
      "At depth 2 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5367892976588627\n",
      "AUC-ROC score = 0.8365526901705151\n",
      "\n",
      "At depth 2 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5349999999999999\n",
      "AUC-ROC score = 0.8384003684455793\n",
      "\n",
      "At depth 2 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5546942291128337\n",
      "AUC-ROC score = 0.8387839388249528\n",
      "\n",
      "At depth 3 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5736170212765958\n",
      "AUC-ROC score = 0.8533078346464202\n",
      "\n",
      "At depth 3 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5721605465414176\n",
      "AUC-ROC score = 0.8537915557287564\n",
      "\n",
      "At depth 3 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5728900255754475\n",
      "AUC-ROC score = 0.8520896750756921\n",
      "\n",
      "At depth 3 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5729076790336497\n",
      "AUC-ROC score = 0.8518410015615334\n",
      "\n",
      "At depth 3 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5736301369863014\n",
      "AUC-ROC score = 0.8520603792918321\n",
      "\n",
      "At depth 4 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5891748003549246\n",
      "AUC-ROC score = 0.8623472872104145\n",
      "\n",
      "At depth 4 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5915996425379804\n",
      "AUC-ROC score = 0.8634073858077596\n",
      "\n",
      "At depth 4 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5947888589398024\n",
      "AUC-ROC score = 0.8635886108893109\n",
      "\n",
      "At depth 4 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5899280575539567\n",
      "AUC-ROC score = 0.8626368385625173\n",
      "\n",
      "At depth 4 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.592057761732852\n",
      "AUC-ROC score = 0.8629011819145543\n",
      "\n",
      "At depth 5 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5985401459854015\n",
      "AUC-ROC score = 0.8692004567417091\n",
      "\n",
      "At depth 5 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6009132420091324\n",
      "AUC-ROC score = 0.8701624485279891\n",
      "\n",
      "At depth 5 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5967153284671534\n",
      "AUC-ROC score = 0.869733231229578\n",
      "\n",
      "At depth 5 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5948905109489051\n",
      "AUC-ROC score = 0.8696542007428866\n",
      "\n",
      "At depth 5 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5954337899543379\n",
      "AUC-ROC score = 0.8696937159862325\n",
      "\n",
      "At depth 6 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6148148148148148\n",
      "AUC-ROC score = 0.8744055681065659\n",
      "\n",
      "At depth 6 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6215213358070502\n",
      "AUC-ROC score = 0.8748906517835001\n",
      "\n",
      "At depth 6 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6168051708217913\n",
      "AUC-ROC score = 0.8749683196755935\n",
      "\n",
      "At depth 6 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6148215919487647\n",
      "AUC-ROC score = 0.874754392323687\n",
      "\n",
      "At depth 6 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6129917657822507\n",
      "AUC-ROC score = 0.8748361479995749\n",
      "\n",
      "At depth 7 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6145146088595663\n",
      "AUC-ROC score = 0.8753907240010138\n",
      "\n",
      "At depth 7 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6173752310536044\n",
      "AUC-ROC score = 0.8769577077888632\n",
      "\n",
      "At depth 7 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6155268022181146\n",
      "AUC-ROC score = 0.8770667153567138\n",
      "\n",
      "At depth 7 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6123959296947271\n",
      "AUC-ROC score = 0.8770735283297042\n",
      "\n",
      "At depth 7 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6149584487534625\n",
      "AUC-ROC score = 0.8771471084380034\n",
      "\n",
      "At depth 8 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6291706387035272\n",
      "AUC-ROC score = 0.878486538927965\n",
      "\n",
      "At depth 8 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6285178236397748\n",
      "AUC-ROC score = 0.8789116684425816\n",
      "\n",
      "At depth 8 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6285178236397748\n",
      "AUC-ROC score = 0.8782317337381148\n",
      "\n",
      "At depth 8 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6278195488721805\n",
      "AUC-ROC score = 0.8780109934132176\n",
      "\n",
      "At depth 8 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6291079812206573\n",
      "AUC-ROC score = 0.8783475542789558\n",
      "\n",
      "At depth 9 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6379647749510762\n",
      "AUC-ROC score = 0.8782003940623577\n",
      "\n",
      "At depth 9 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6336248785228378\n",
      "AUC-ROC score = 0.8790424775240021\n",
      "\n",
      "At depth 9 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6329113924050634\n",
      "AUC-ROC score = 0.8784402107116286\n",
      "\n",
      "At depth 9 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6316812439261419\n",
      "AUC-ROC score = 0.8778733713588066\n",
      "\n",
      "At depth 9 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6321951219512195\n",
      "AUC-ROC score = 0.8784674626035912\n",
      "\n",
      "At depth 10 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6478304742684157\n",
      "AUC-ROC score = 0.8752939797845466\n",
      "\n",
      "At depth 10 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6426426426426427\n",
      "AUC-ROC score = 0.8774182647630312\n",
      "\n",
      "At depth 10 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6432160804020101\n",
      "AUC-ROC score = 0.8777452874665824\n",
      "\n",
      "At depth 10 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6446446446446447\n",
      "AUC-ROC score = 0.877982378926657\n",
      "\n",
      "At depth 10 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6473526473526474\n",
      "AUC-ROC score = 0.8782930504950306\n",
      "\n",
      "At depth 11 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6479166666666667\n",
      "AUC-ROC score = 0.8754534033525277\n",
      "\n",
      "At depth 11 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6450261780104711\n",
      "AUC-ROC score = 0.8764126699496114\n",
      "\n",
      "At depth 11 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.639412997903564\n",
      "AUC-ROC score = 0.8757136589207706\n",
      "\n",
      "At depth 11 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6408376963350786\n",
      "AUC-ROC score = 0.8751004913516122\n",
      "\n",
      "At depth 11 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6367432150313154\n",
      "AUC-ROC score = 0.8752939797845467\n",
      "\n",
      "At depth 12 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6369565217391304\n",
      "AUC-ROC score = 0.8736084502666598\n",
      "\n",
      "At depth 12 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.643010752688172\n",
      "AUC-ROC score = 0.8755910254069388\n",
      "\n",
      "At depth 12 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6392199349945829\n",
      "AUC-ROC score = 0.8768146353560596\n",
      "\n",
      "At depth 12 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6391304347826087\n",
      "AUC-ROC score = 0.8758253916778171\n",
      "\n",
      "At depth 12 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6385281385281384\n",
      "AUC-ROC score = 0.8759003343807144\n",
      "\n",
      "At depth 13 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6455981941309256\n",
      "AUC-ROC score = 0.8712886329633436\n",
      "\n",
      "At depth 13 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6456692913385826\n",
      "AUC-ROC score = 0.8738005761049961\n",
      "\n",
      "At depth 13 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6454545454545454\n",
      "AUC-ROC score = 0.8728426721025109\n",
      "\n",
      "At depth 13 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6403607666290868\n",
      "AUC-ROC score = 0.8734244999959122\n",
      "\n",
      "At depth 13 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6404494382022472\n",
      "AUC-ROC score = 0.8732051222656132\n",
      "\n",
      "At depth 14 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6412037037037037\n",
      "AUC-ROC score = 0.8696569259320829\n",
      "\n",
      "At depth 14 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6441860465116278\n",
      "AUC-ROC score = 0.8714024096122874\n",
      "\n",
      "At depth 14 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.641860465116279\n",
      "AUC-ROC score = 0.8704921964207364\n",
      "\n",
      "At depth 14 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6420323325635103\n",
      "AUC-ROC score = 0.8711339784764558\n",
      "\n",
      "At depth 14 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6428571428571429\n",
      "AUC-ROC score = 0.8719637985867168\n",
      "\n",
      "At depth 15 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6357142857142857\n",
      "AUC-ROC score = 0.8668894963032808\n",
      "\n",
      "At depth 15 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6379928315412187\n",
      "AUC-ROC score = 0.8695261168506624\n",
      "\n",
      "At depth 15 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6461538461538461\n",
      "AUC-ROC score = 0.8704349674476152\n",
      "\n",
      "At depth 15 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6374407582938388\n",
      "AUC-ROC score = 0.8700180135005873\n",
      "\n",
      "At depth 15 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6421800947867298\n",
      "AUC-ROC score = 0.8706502573941195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "n_estimator_list = [100, 200, 300, 400, 500]\n",
    "\n",
    "for depth in max_depth_list:\n",
    "    for n_estimator in n_estimator_list:\n",
    "        model_rf = RandomForestClassifier(max_depth = depth, n_estimators = n_estimator, random_state = 42)\n",
    "\n",
    "        model_rf.fit(features_upsampled, target_upsampled)\n",
    "        predictions_valid_rf = model_rf.predict(features_valid)\n",
    "        probabalities_valid_rf = model_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "        print(\"At depth\", depth, \"and n_estimator\", n_estimator, \"F1 score and AUC-SCORE is:\", end='')\n",
    "        print()\n",
    "        print('F1 score =', f1_score(target_valid, predictions_valid_rf))\n",
    "        print('AUC-ROC score =', roc_auc_score(target_valid, probabalities_valid_rf))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "1. Based on the performance results of the models after upsampling, the F1 scores from highest to lowest are as follows:\n",
    "   - Random Forest model with depth = 11 and n_estimators = 100, F1 score = 0.647 and AUC-ROC score = 0.875\n",
    "   - Decision Tree model with depth = 5, F1 score = 0.57 and AUC-ROC score = 0.83\n",
    "   - Logistic Regression model with F1 score = 0.51 and AUC-ROC score = 0.79\n",
    "\n",
    "2.  The results of Random Forest passed the evaluation with a minimum F1 score of 0.59 for the validation set.\n",
    "\n",
    "3. Comparison of the three models before scaling, after scaling, after class weight adjustment, and after upsampling is as follows:\n",
    "    3.1. Logistic Regression\n",
    "    \n",
    "        3.1.1 Before scaling: F1 score = 0.11 and AUC-ROC = 0.67\n",
    "\n",
    "        3.1.2 After scaling: F1 score = 0.35 and AUC-ROC = 0.79\n",
    "        \n",
    "        3.1.3 After class weight adjustment: F1 score = 0.51 and AUC-ROC = 0.79\n",
    "\n",
    "        3.1.4 After upsampling: F1 score = 0.51 and AUC-ROC score = 0.79\n",
    "        \n",
    "    3.2. Decision Tree\n",
    "\n",
    "        3.2.1 Before scaling: F1 score = 0.47 and AUC-ROC score = 0.67\n",
    "\n",
    "        3.2.2 After scaling: F1 score = 0.50 and AUC-ROC score = 0.69\n",
    "\n",
    "        3.2.3 After class weight adjustment: F1 score = 0.57 and AUC-ROC score = 0.82\n",
    "\n",
    "        3.2.4 After upsampling: F1 score = 0.57 and AUC-ROC score = 0.83\n",
    "        \n",
    "    3.3. Random Forest\n",
    "    \n",
    "        3.3.1 Before scaling: F1 score = 0.61 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.2 After scaling: F1 score = 0.61 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.3 After class weight adjustment: F1 score = 0.66 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.4 After upsampling: F1 score = 0.64 and AUC-ROC score = 0.875\n",
    "        \n",
    "\n",
    "4. From the information above, it can be seen that the F1 score of the three models tends to remain stagnant or even decrease (for Random Forest) when using upsampling to handle imbalance compared to class_weight adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Downsampling <a id='downsampling'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample (features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state = 42)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state = 42)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle (features_downsampled, target_downsampled, random_state = 42)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exited\n",
       "0    5068\n",
       "1    1307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data composition\n",
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exited\n",
       "0    1520\n",
       "1    1307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data composition after upsampling\n",
    "target_downsampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score = 0.5316455696202531\n",
      "AUC-ROC score = 0.7965823402289703\n"
     ]
    }
   ],
   "source": [
    "downsample_lr = LogisticRegression(random_state = 42)\n",
    "\n",
    "# train model on training set\n",
    "downsample_lr.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_lr = downsample_lr.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_lr = downsample_lr.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('F1 score =', f1_score(target_valid, y_predict_valid_lr))\n",
    "print('AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At max_depth 1 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.48982667671439334\n",
      "AUC-ROC score = 0.7064760033465324\n",
      "\n",
      "At max_depth 2 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.4989733059548255\n",
      "AUC-ROC score = 0.754864462715324\n",
      "\n",
      "At max_depth 3 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5655577299412915\n",
      "AUC-ROC score = 0.8086474340981122\n",
      "\n",
      "At max_depth 4 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.546400693842151\n",
      "AUC-ROC score = 0.8460765451141445\n",
      "\n",
      "At max_depth 5 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5748917748917749\n",
      "AUC-ROC score = 0.8471931913873121\n",
      "\n",
      "At max_depth 6 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5826235093696763\n",
      "AUC-ROC score = 0.8361902400074124\n",
      "\n",
      "At max_depth 7 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5760765550239234\n",
      "AUC-ROC score = 0.8316698324281163\n",
      "\n",
      "At max_depth 8 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5719489981785063\n",
      "AUC-ROC score = 0.8180363921765268\n",
      "\n",
      "At max_depth 9 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5678119349005425\n",
      "AUC-ROC score = 0.8058547964692448\n",
      "\n",
      "At max_depth 10 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5488454706927175\n",
      "AUC-ROC score = 0.7743611475226668\n",
      "\n",
      "At max_depth 11 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5370051635111875\n",
      "AUC-ROC score = 0.7623519200320481\n",
      "\n",
      "At max_depth 12 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5268630849220104\n",
      "AUC-ROC score = 0.7436925496052564\n",
      "\n",
      "At max_depth 13 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5139475908706678\n",
      "AUC-ROC score = 0.7365239394244946\n",
      "\n",
      "At max_depth 14 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5139005897219882\n",
      "AUC-ROC score = 0.7317868793040958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 15):\n",
    "    model_dtree = DecisionTreeClassifier(max_depth=depth, random_state = 42)\n",
    "    model_dtree.fit(features_downsampled, target_downsampled)\n",
    "    predictions_valid_dtree = model_dtree.predict(features_valid)\n",
    "    probabalities_valid_dtree = model_dtree.predict_proba(features_valid)[:, 1]\n",
    "    \n",
    "    print(\"At max_depth\", depth, \"F1 score and AUC-SCORE is:\", end='')\n",
    "    print()\n",
    "    print('F1 score =', f1_score(target_valid, predictions_valid_dtree))\n",
    "    print('AUC-ROC score =', roc_auc_score(target_valid, probabalities_valid_dtree))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At depth 1 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5927770859277708\n",
      "AUC-ROC score = 0.8402746173153073\n",
      "\n",
      "At depth 1 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5696040868454663\n",
      "AUC-ROC score = 0.8419989807792406\n",
      "\n",
      "At depth 1 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5768321513002364\n",
      "AUC-ROC score = 0.8341252278939466\n",
      "\n",
      "At depth 1 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5707547169811321\n",
      "AUC-ROC score = 0.8331196330805266\n",
      "\n",
      "At depth 1 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5813664596273292\n",
      "AUC-ROC score = 0.8351301414100674\n",
      "\n",
      "At depth 2 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6053169734151329\n",
      "AUC-ROC score = 0.855453921138475\n",
      "\n",
      "At depth 2 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5981688708036622\n",
      "AUC-ROC score = 0.8554198562735217\n",
      "\n",
      "At depth 2 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5952380952380952\n",
      "AUC-ROC score = 0.8526830850231777\n",
      "\n",
      "At depth 2 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.595617529880478\n",
      "AUC-ROC score = 0.8523281291303648\n",
      "\n",
      "At depth 2 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.598790322580645\n",
      "AUC-ROC score = 0.8527028426448505\n",
      "\n",
      "At depth 3 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.5947521865889212\n",
      "AUC-ROC score = 0.8634223743483391\n",
      "\n",
      "At depth 3 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6033300685602351\n",
      "AUC-ROC score = 0.8645560530539833\n",
      "\n",
      "At depth 3 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6001955034213099\n",
      "AUC-ROC score = 0.8628712048333955\n",
      "\n",
      "At depth 3 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6029556650246305\n",
      "AUC-ROC score = 0.8627676476439377\n",
      "\n",
      "At depth 3 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6051587301587301\n",
      "AUC-ROC score = 0.862426317697106\n",
      "\n",
      "At depth 4 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6081871345029239\n",
      "AUC-ROC score = 0.8703968147988673\n",
      "\n",
      "At depth 4 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.619140625\n",
      "AUC-ROC score = 0.8718220887485114\n",
      "\n",
      "At depth 4 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6182170542635659\n",
      "AUC-ROC score = 0.8716762911265115\n",
      "\n",
      "At depth 4 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6098741529525654\n",
      "AUC-ROC score = 0.8708410206378577\n",
      "\n",
      "At depth 4 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6153846153846153\n",
      "AUC-ROC score = 0.8710236083140073\n",
      "\n",
      "At depth 5 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6167315175097275\n",
      "AUC-ROC score = 0.8782399093057034\n",
      "\n",
      "At depth 5 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6197458455522971\n",
      "AUC-ROC score = 0.876441284436172\n",
      "\n",
      "At depth 5 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6186770428015564\n",
      "AUC-ROC score = 0.8764044943820224\n",
      "\n",
      "At depth 5 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6192794547224928\n",
      "AUC-ROC score = 0.8760352312459293\n",
      "\n",
      "At depth 5 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6204878048780487\n",
      "AUC-ROC score = 0.8755106323256494\n",
      "\n",
      "At depth 6 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6243902439024391\n",
      "AUC-ROC score = 0.8791950881189926\n",
      "\n",
      "At depth 6 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.624031007751938\n",
      "AUC-ROC score = 0.8795629886604878\n",
      "\n",
      "At depth 6 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6226964112512123\n",
      "AUC-ROC score = 0.8793599620653662\n",
      "\n",
      "At depth 6 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6228239845261121\n",
      "AUC-ROC score = 0.87916783622703\n",
      "\n",
      "At depth 6 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6253630203291384\n",
      "AUC-ROC score = 0.8791446721188619\n",
      "\n",
      "At depth 7 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6266924564796904\n",
      "AUC-ROC score = 0.8806408009876087\n",
      "\n",
      "At depth 7 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6254826254826255\n",
      "AUC-ROC score = 0.8825048303978503\n",
      "\n",
      "At depth 7 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6208897485493231\n",
      "AUC-ROC score = 0.881977506288374\n",
      "\n",
      "At depth 7 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6258503401360543\n",
      "AUC-ROC score = 0.8817308766661125\n",
      "\n",
      "At depth 7 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6258503401360543\n",
      "AUC-ROC score = 0.8816273194766546\n",
      "\n",
      "At depth 8 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6301633045148896\n",
      "AUC-ROC score = 0.8805822094198891\n",
      "\n",
      "At depth 8 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.625968992248062\n",
      "AUC-ROC score = 0.8818235330987854\n",
      "\n",
      "At depth 8 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6263208453410183\n",
      "AUC-ROC score = 0.8814856096384491\n",
      "\n",
      "At depth 8 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6287367405978784\n",
      "AUC-ROC score = 0.8811885640160568\n",
      "\n",
      "At depth 8 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6312741312741313\n",
      "AUC-ROC score = 0.8811981021782436\n",
      "\n",
      "At depth 9 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6245210727969349\n",
      "AUC-ROC score = 0.8794417177412542\n",
      "\n",
      "At depth 9 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6321839080459771\n",
      "AUC-ROC score = 0.8803219538516462\n",
      "\n",
      "At depth 9 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6283524904214559\n",
      "AUC-ROC score = 0.8799499655263566\n",
      "\n",
      "At depth 9 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6288461538461539\n",
      "AUC-ROC score = 0.8798682098504688\n",
      "\n",
      "At depth 9 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6223506743737958\n",
      "AUC-ROC score = 0.8799390647695715\n",
      "\n",
      "At depth 10 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6358381502890172\n",
      "AUC-ROC score = 0.8810482167724495\n",
      "\n",
      "At depth 10 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6328871892925431\n",
      "AUC-ROC score = 0.8804663888790479\n",
      "\n",
      "At depth 10 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6313763233878729\n",
      "AUC-ROC score = 0.8792359659569366\n",
      "\n",
      "At depth 10 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6320845341018251\n",
      "AUC-ROC score = 0.8794226414168805\n",
      "\n",
      "At depth 10 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6283524904214559\n",
      "AUC-ROC score = 0.8792945575246562\n",
      "\n",
      "At depth 11 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6295585412667946\n",
      "AUC-ROC score = 0.8767206163287886\n",
      "\n",
      "At depth 11 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6309751434034417\n",
      "AUC-ROC score = 0.8791542102810488\n",
      "\n",
      "At depth 11 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.633816425120773\n",
      "AUC-ROC score = 0.8792645804434973\n",
      "\n",
      "At depth 11 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6326923076923077\n",
      "AUC-ROC score = 0.8786486876851424\n",
      "\n",
      "At depth 11 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6314779270633396\n",
      "AUC-ROC score = 0.8787563326583948\n",
      "\n",
      "At depth 12 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6319845857418112\n",
      "AUC-ROC score = 0.8782181077921335\n",
      "\n",
      "At depth 12 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6296650717703348\n",
      "AUC-ROC score = 0.8790697294159646\n",
      "\n",
      "At depth 12 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6259541984732824\n",
      "AUC-ROC score = 0.8783461916843576\n",
      "\n",
      "At depth 12 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6270373921380633\n",
      "AUC-ROC score = 0.8773256083303582\n",
      "\n",
      "At depth 12 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6307692307692307\n",
      "AUC-ROC score = 0.8769536200050688\n",
      "\n",
      "At depth 13 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6161048689138576\n",
      "AUC-ROC score = 0.8749785391350794\n",
      "\n",
      "At depth 13 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6244087038789026\n",
      "AUC-ROC score = 0.8763595287602842\n",
      "\n",
      "At depth 13 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6187739463601533\n",
      "AUC-ROC score = 0.8755528727581914\n",
      "\n",
      "At depth 13 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6265520534861508\n",
      "AUC-ROC score = 0.8767723949235176\n",
      "\n",
      "At depth 13 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6245210727969349\n",
      "AUC-ROC score = 0.8770231123295735\n",
      "\n",
      "At depth 14 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6233269598470363\n",
      "AUC-ROC score = 0.8715747778289509\n",
      "\n",
      "At depth 14 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6286799620132955\n",
      "AUC-ROC score = 0.8732398684278655\n",
      "\n",
      "At depth 14 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6241674595623216\n",
      "AUC-ROC score = 0.8737515226994632\n",
      "\n",
      "At depth 14 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6190476190476191\n",
      "AUC-ROC score = 0.8740880835652014\n",
      "\n",
      "At depth 14 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6221374045801527\n",
      "AUC-ROC score = 0.8738060264833886\n",
      "\n",
      "At depth 15 and n_estimator 100 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6281929990539262\n",
      "AUC-ROC score = 0.8706727402049887\n",
      "\n",
      "At depth 15 and n_estimator 200 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6252354048964218\n",
      "AUC-ROC score = 0.8728556167511929\n",
      "\n",
      "At depth 15 and n_estimator 300 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6191832858499526\n",
      "AUC-ROC score = 0.8738189711320707\n",
      "\n",
      "At depth 15 and n_estimator 400 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6206244087038789\n",
      "AUC-ROC score = 0.8742379689709957\n",
      "\n",
      "At depth 15 and n_estimator 500 F1 score and AUC-SCORE is:\n",
      "F1 score = 0.6191832858499526\n",
      "AUC-ROC score = 0.8743742284308087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_depth_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "n_estimator_list = [100, 200, 300, 400, 500]\n",
    "\n",
    "for depth in max_depth_list:\n",
    "    for n_estimator in n_estimator_list:\n",
    "        model_rf = RandomForestClassifier(max_depth = depth, n_estimators = n_estimator, random_state = 42)\n",
    "\n",
    "        model_rf.fit(features_downsampled, target_downsampled)\n",
    "        predictions_valid_rf = model_rf.predict(features_valid)\n",
    "        probabalities_valid_rf = model_rf.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "        print(\"At depth\", depth, \"and n_estimator\", n_estimator, \"F1 score and AUC-SCORE is:\", end='')\n",
    "        print()\n",
    "        print('F1 score =', f1_score(target_valid, predictions_valid_rf))\n",
    "        print('AUC-ROC score =', roc_auc_score(target_valid, probabalities_valid_rf))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "1. Based on the performance results of the models after downsampling, the F1 scores from highest to lowest are as follows:\n",
    "   - Random Forest model with depth = 10 and n_estimators = 100, F1 score = 0.635 and AUC-ROC score = 0.88\n",
    "   - Decision Tree model with depth = 6, F1 score = 0.58 and AUC-ROC score = 0.83\n",
    "   - Logistic Regression model with F1 score = 0.53 and AUC-ROC score = 0.79\n",
    "\n",
    "2. The results of Random Forest passed the evaluation with a minimum F1 score of 0.59 for the validation set.\n",
    "\n",
    "3. Comparison of the three models before scaling, after scaling, after class weight adjustment, after upsampling, and after downsampling is as follows:\n",
    "\n",
    "     3.1. Logistic Regression\n",
    "    \n",
    "        3.1.1 Before scaling: F1 score = 0.11 and AUC-ROC = 0.67\n",
    "\n",
    "        3.1.2 After scaling: F1 score = 0.35 and AUC-ROC = 0.79\n",
    "        \n",
    "        3.1.3 After class weight adjustment: F1 score = 0.51 and AUC-ROC = 0.79\n",
    "\n",
    "        3.1.4 After upsampling: F1 score = 0.51 and AUC-ROC score = 0.79\n",
    "\n",
    "        3.1.5 After downsampling: F1 score = 0.53 and AUC-ROC score = 0.79\n",
    "        \n",
    "    3.2. Decision Tree\n",
    "\n",
    "        3.2.1 Before scaling: F1 score = 0.47 and AUC-ROC score = 0.67\n",
    "\n",
    "        3.2.2 After scaling: F1 score = 0.50 and AUC-ROC score = 0.69\n",
    "\n",
    "        3.2.3 After class weight adjustment: F1 score = 0.57 and AUC-ROC score = 0.82\n",
    "\n",
    "        3.2.4 After upsampling: F1 score = 0.57 and AUC-ROC score = 0.83\n",
    "        \n",
    "        3.2.5 After downsampling: F1 score = 0.58 and AUC-ROC score = 0.83\n",
    "        \n",
    "    3.3. Random Forest\n",
    "    \n",
    "        3.3.1 Before scaling: F1 score = 0.61 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.2 After scaling: F1 score = 0.61 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.3 After class weight adjustment: F1 score = 0.66 and AUC-ROC score = 0.87\n",
    "\n",
    "        3.3.4 After upsampling: F1 score = 0.64 and AUC-ROC score = 0.875\n",
    "\n",
    "        3.3.5 After downsampling: F1 score = 0.635 and AUC-ROC score = 0.88\n",
    "\n",
    "4. From the information above, it can be seen that the F1 score of the three models tends to remain stagnant or even decrease (for Random Forest) when using aftersampling to handle imbalance compared to class_weight adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of Improving Model's Quality Step <a id='after_improving_conclusions'></a>\n",
    "\n",
    "From the three processes (class_weight adjustment, upsampling, downsampling), the best F1 score is achieved by:\n",
    "- Model: Random Forest\n",
    "- Method: hyperparameter tuning (class weight adjustment)\n",
    "- Depth: 10\n",
    "- n_estimators: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Testing Model on Test Dataset <a id='testing_model'></a>\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on validation set, F1 score = 0.6622516556291391\n",
      "on validation set, AUC-ROC score = 0.8765584675716112\n"
     ]
    }
   ],
   "source": [
    "final_model = RandomForestClassifier(max_depth = 10, n_estimators = 100, class_weight = 'balanced', random_state = 42)\n",
    "\n",
    "# train model on training set\n",
    "final_model.fit(features_train, target_train)\n",
    "\n",
    "#  predict using validation set\n",
    "y_predict_valid_lr = final_model.predict(features_valid)\n",
    "\n",
    "# measuring probability using validation set\n",
    "y_probability_valid_lr = final_model.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# test performance algorithm using F1 score and auc_score\n",
    "print('on validation set, F1 score =', f1_score(target_valid, y_predict_valid_lr))\n",
    "print('on validation set, AUC-ROC score =', roc_auc_score(target_valid, y_probability_valid_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on dataset test, F1 score = 0.5915966386554622\n",
      "on dataset test, AUC-ROC score = 0.8517582158570531\n"
     ]
    }
   ],
   "source": [
    "# test dataset\n",
    "predicted_test = final_model.predict(features_test)\n",
    "probabilities_test = final_model.predict_proba(features_test)[:, 1]\n",
    "\n",
    "print('on dataset test, F1 score =', f1_score(target_test, predicted_test))\n",
    "print('on dataset test, AUC-ROC score =', roc_auc_score(target_test, probabilities_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Conclusion <a id='end'></a>\n",
    "\n",
    "The F1_score on the test dataset is 0.59, which meets the minimum requirement, and the AUC-ROC score is 0.85.\n",
    "\n",
    "Therefore, I would recommend Bank Beta to use the Random Forest model with a depth of 10 and n_estimators of 100 to predict whether a customer is likely to leave the bank or not.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.293px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
